{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrect Keras Notebook\n",
    "<a href=\"https://colab.research.google.com/github/hacksaremeta/IS-Sentence-Completion/blob/datasets/src/autocorrect_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DJfRQZSgWEU"
   },
   "source": [
    "## Sentence completion using a LSTM RNN (with TF2 Keras)  \n",
    "For a general idea on how this works see [Tensorflow Docs: Text generation with an RNN](https://www.tensorflow.org/text/tutorials/text_generation) and [Will Koehrsen: RNNs by Example in Python](https://towardsdatascience.com/recurrent-neural-networks-by-example-in-python-ffd204f99470).\n",
    "In this case the sequences given are words instead of characters and the RNN predicts the next word.\n",
    "Therefore we use the Keras Tokenizer to convert sentences to vectors of word representatives (integers).\n",
    "After tokenization each 'word' will be converted to a feature vector using Keras pre-trained embeddings.\n",
    "Then we train the network by giving it n 'words' (features) from the PubMed training data and having it predict the (n+1)-th word (label) in the sequence.\n",
    "The predicted word is then compared to the actual word present in the training data and back-propagation is used to tweak the network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] DataManager: Dataset already exists, skipping fetch\n"
     ]
    }
   ],
   "source": [
    "%run dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Masking, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "H_DQrwTagWEY",
    "outputId": "d069f3db-b8dd-462a-9cc0-85479051eb8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] DataManager: Dataset already exists, skipping fetch\n",
      "[DEBUG] Main: First extracted abstract: Long noncoding RNA nuclear paraspeckle assembly transcript 1 (lncRNA NEAT1) is abnormally expressed in numerous tumors and functions as an oncogene, but the role of NEAT1 in laryngocarcinoma is largely unknown. Our study validated that NEAT1 expression was markedly upregulated in laryngocarcinoma tissues and cells. Downregulation of NEAT1 dramatically suppressed cell proliferation and invasion through inhibiting miR-524-5p expression. Additionally, NEAT1 overexpression promoted cell growth and metastasis, while overexpression of miR-524-5p could reverse the effect. NEAT1 increased the expression of histone deacetylase 1 gene (HDAC1) via sponging miR-524-5p. Mechanistically, overexpression of HDAC1 recovered the cancer-inhibiting effects of miR-524-5p mimic or NEAT1 silence by deacetylation of tensin homolog deleted on chromosome ten (PTEN) and inhibiting AKT signal pathway. Moreover, in vivo experiments indicated that silence of NEAT1 signally suppressed tumor growth. Taken together, knockdown of NEAT1 suppressed laryngocarcinoma cell growth and metastasis by miR-524-5p/HDAC1/PTEN/AKT signal pathway, which provided a potential therapeutic target for laryngocarcinoma.\n",
      "[DEBUG] Main: First tokenized sequence: [506, 291, 29, 292, 507, 508, 509, 34, 510, 39, 9, 511, 293, 4, 512, 294, 3, 513, 13, 30, 514, 127, 1, 128, 2, 39, 4, 171, 9, 295, 515, 63, 21, 192, 14, 39, 8, 7, 516, 262, 4, 171, 114, 3, 263, 517, 2, 39, 518, 129, 19, 35, 3, 130, 48, 172, 28, 264, 173, 1106, 296, 39, 131, 193, 19, 174, 3, 265, 297, 131, 2, 28, 264, 173, 194, 90, 1, 1107, 39, 40, 1, 8, 2, 298, 519, 34, 31, 299, 520, 521, 28, 264, 1108, 522, 131, 2, 299, 300, 1, 64, 172, 115, 2, 28, 264, 173, 523, 49, 39, 301, 15, 524, 2, 525, 526, 527, 42, 528, 529, 175, 3, 172, 530, 50, 447, 531, 4, 195, 532, 302, 14, 301, 2, 39, 533, 129, 132, 1109, 303, 304, 305, 2, 39, 129, 171, 19, 174, 3, 265, 15, 28, 264, 1110, 50, 116, 24, 306, 6, 25, 133, 91, 10, 1111]\n",
      "[DEBUG] Main: First extracted feature: long noncoding rna nuclear paraspeckle assembly transcript 1 lncrna neat1 is abnormally expressed in numerous tumors and functions as an [506, 291, 29, 292, 507, 508, 509, 34, 510, 39, 9, 511, 293, 4, 512, 294, 3, 513, 13, 30]\n",
      "[DEBUG] Main: First extracted label: oncogene [514]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Init logging\n",
    "    logging.basicConfig(level=logging.DEBUG, format='[%(levelname)s] %(name)s: %(message)s')\n",
    "    log = logging.getLogger(\"Main\")\n",
    "\n",
    "    # Create DataManager in '../res/datasets' folder\n",
    "    data_folder = os.path.join(\"..\", \"res\", \"datasets\")\n",
    "    dman = DataManager(\"mymail@example.com\", data_folder)\n",
    "\n",
    "    dataset_name = \"RNA Dataset\"\n",
    "    queries = [\"RNA\", \"mRNA\", \"tRNA\"]\n",
    "\n",
    "    # Gather maximum of 100 abstracts for each query\n",
    "    # I would suggest around 5 - 20 abstracts in total for the small data sets\n",
    "    # and maybe 500 - 5000 for the final ones but we'll have to test\n",
    "    # since that depends on how long it takes to train the network\n",
    "    # This only queries PubMed if data if the data is not already present\n",
    "    dman.create_dataset(queries, dataset_name, 5)\n",
    "\n",
    "    # Load the dataset\n",
    "    abstracts = dman.load_full_dataset(dataset_name)\n",
    "    abstracts_mrna = dman.load_query_from_dataset(dataset_name, queries[1])\n",
    "\n",
    "    ab = dman.remove_punctuation(dataset_name)\n",
    "\n",
    "    assert(len(ab) > 0)\n",
    "    log.debug(f\"First extracted abstract: {ab[0]}\")\n",
    "\n",
    "    # Tokenize abstracts\n",
    "    # See https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "    # Filters slightly modified (comp. to docs) to keep punctuation\n",
    "    # Lowercase has to be used for pre-trained embeddings\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=None, \n",
    "        filters='#$%&()*+-,<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "        lower = True, split = ' '\n",
    "    )\n",
    "\n",
    "    tokenizer.fit_on_texts(ab)\n",
    "\n",
    "    # Generates list of lists of integers\n",
    "    # Can be reversed with the sequences_to_texts() function of the tokenizer\n",
    "    sequences = tokenizer.texts_to_sequences(ab)\n",
    "\n",
    "    assert(len(sequences) > 0)\n",
    "    log.debug(f\"First tokenized sequence: {sequences[0]}\")\n",
    "\n",
    "    # Prepare training data\n",
    "    # Extract features and labels\n",
    "    # Number of words before prediction: num_pred\n",
    "    num_pred = 20\n",
    "    features, labels = DataUtils.extract_features_and_labels(sequences, 20)\n",
    "\n",
    "    assert(len(features) > 0 and len(labels) > 0)\n",
    "    log.debug(f\"First extracted feature: {tokenizer.sequences_to_texts(features)[0]} {features[0]}\")\n",
    "    log.debug(f\"First extracted label: {tokenizer.index_word[labels[0]]} [{labels[0]}]\")\n",
    "\n",
    "    # Create Keras LSTM RNN model\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
